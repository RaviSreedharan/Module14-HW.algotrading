{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "```\n",
    "1. Working on data downloaded from BINANCE by Justin\n",
    "2. Split data into training and test\n",
    "3. Fit the model(s) to the training data\n",
    "4. Evaluate the trained model(s) by using testing data (including calculations, metrics, or visualizations needed to evaluate the performance).\n",
    "5. Optionally, apply a dimensionality reduction technique to reduce the input features, or perform feature engineering to generate new features to train the model.\n",
    "6. Show the predictions by using a sample of new data. Compare the predictions if more than one model is used.\n",
    "7. Save PNG images of your visualizations to distribute to the class and instructional team, as well as to include in your presentation and your repoâ€™s README.md file.\n",
    "8. Use one new machine learning library, machine learning model, or evaluation metric that hasn't been covered in class.\n",
    "9. Create a README.md in your repo with a write-up summarizing your project. Be sure to include any usage instructions to set up and use the model.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get eth daily candle from 2016-2022\n",
    "candles = client.get_historical_klines(\"ETHUSDT\", Client.KLINE_INTERVAL_1DAY, \"1 Dec, 2016\", \"1 Dec, 2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set list to hold candle data\n",
    "open = []\n",
    "high = []\n",
    "low = []\n",
    "close = []\n",
    "volume = []\n",
    "time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loop that adds data to lists above\n",
    "for i in range(len(candles)):\n",
    "    open.append(candles[i][1])\n",
    "    high.append(candles[i][2])\n",
    "    low.append(candles[i][3])\n",
    "    close.append(candles[i][4])\n",
    "    volume.append(candles[i][5])\n",
    "    time.append(candles[i][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "candle_df_open = pd.DataFrame(open, columns= ['open'])\n",
    "candle_df_high = pd.DataFrame(high, columns= ['high'])\n",
    "candle_df_low = pd.DataFrame(low, columns= ['low'])\n",
    "candle_df_close = pd.DataFrame(close, columns= ['close'])\n",
    "candle_df_volume = pd.DataFrame(volume, columns= ['volume'])\n",
    "candle_df_time = pd.DataFrame(time, columns= ['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candle_df = pd.concat([candle_df_open,candle_df_high,candle_df_low,candle_df_close,candle_df_volume, candle_df_time], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candle_df['time'] = pd.to_datetime(candle_df['time'], unit='ms')\n",
    "\n",
    "candle_df['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candle_df = candle_df.set_index('time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candle_df.to_csv('C:/Users/Justin/Rutgers/project-2/Resources/eth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candle_df = candle_df.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_df = candle_df.loc[:,['close']]\n",
    "\n",
    "signals_df['actual returns'] = signals_df['close'].pct_change()\n",
    "\n",
    "signals_df = signals_df.dropna()\n",
    "\n",
    "display(signals_df.head())\n",
    "display(signals_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finta import TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_df['RSI'] = TA.AO(candle_df)\n",
    "#signals_df['STOCH'] = TA.BBWIDTH(candle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_df.head(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the new Signal column\n",
    "signals_df['Signal'] = 0\n",
    "\n",
    "# When Actual Returns are greater than or equal to 0, generate signal to buy stock long\n",
    "signals_df.loc[(signals_df['RSI'] > 0), 'Signal'] = 1\n",
    "\n",
    "# When Actual Returns are less than 0, generate signal to sell stock short\n",
    "signals_df.loc[(signals_df['RSI'] < 0) , 'Signal'] = -1\n",
    "\n",
    "# Review the DataFrame\n",
    "display(signals_df.head())\n",
    "display(signals_df.tail())\n",
    "\n",
    "# When Actual Returns are greater than or equal to 0, generate signal to buy stock long\n",
    "#signals_df.loc[(signals_df['RSI'] <= 35) & (signals_df['STOCH'] < .25 ), 'Signal'] = 1\n",
    "# When Actual Returns are less than 0, generate signal to sell stock short\n",
    "#ignals_df.loc[(signals_df['RSI'] >= 60) & (signals_df['STOCH'] < .25 ), 'Signal'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(signals_df.head())\n",
    "display(signals_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_df['Signal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_df['Strategy Returns'] = signals_df['actual returns'] * signals_df['Signal'].shift().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(signals_df.head())\n",
    "display(signals_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 + signals_df['Strategy Returns']).cumprod().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = signals_df[['RSI']].shift().dropna()\n",
    "\n",
    "y = signals_df['Signal']\n",
    "\n",
    "# Review the value counts\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "\n",
    "# Display the training begin date\n",
    "print(training_begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_end = X.index.min() + DateOffset(months=12)\n",
    "\n",
    "# Display the training end date\n",
    "print(training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Review the X_train DataFrame\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end+DateOffset(months=6):]\n",
    "y_test = y.loc[training_end+DateOffset(months=6):]\n",
    "\n",
    "# Review the X_test DataFrame\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features DataFrames\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From SVM, instantiate SVC classifier model instance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression()\n",
    " \n",
    "# Fit the model to the data using the training data\n",
    "lr_model = lr_model.fit(X_train_scaled,y_train)\n",
    " \n",
    "# Use the testing data to make the model predictions\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Review the model's predicted values\n",
    "lr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_testing_report = classification_report(y_test, lr_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(lr_testing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictions DataFrame\n",
    "predictions_df = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "# Add the SVM model predictions to the DataFrame\n",
    "predictions_df['Predicted'] = lr_pred\n",
    "\n",
    "# Add the actual returns to the DataFrame\n",
    "predictions_df['actual returns'] = signals_df['actual returns']\n",
    "\n",
    "# Add the strategy returns to the DataFrame\n",
    "predictions_df['Trading Algo Returns'] = signals_df['actual returns'] * predictions_df['Predicted'].shift()\n",
    "\n",
    "# Review the DataFrame\n",
    "display(predictions_df.head())\n",
    "display(predictions_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 + predictions_df[[\"actual returns\", \"Trading Algo Returns\"]]).cumprod().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbill_df = pd.read_csv('C:/Users/Justin/Rutgers/project-2/Resources/DGS2 (2).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbill_df = tbill_df.set_index('DATE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_signals_df = pd.concat([candle_df,tbill_df])\n",
    "asd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbill_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b690e6882326b5178da96a43489ad4a3a410df96195acf222b6fc0fcea8e80e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
